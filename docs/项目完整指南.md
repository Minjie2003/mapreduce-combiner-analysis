# Hadoopè·¨ç‰©ç†æœºåˆ†å¸ƒå¼é›†ç¾¤æ­å»ºæŒ‡å—

## ğŸ“‹ é¡¹ç›®æ€»è§ˆ

**ç›®æ ‡**: é€šè¿‡å®éªŒéªŒè¯Combineråœ¨ä¸åŒæ•°æ®åˆ†å¸ƒä¸‹å¯¹MapReduceæ€§èƒ½çš„å½±å“

### ç ”ç©¶å†…å®¹

1. åˆ†æCombineråœ¨MapReduceæ‰§è¡Œè¿‡ç¨‹ä¸­çš„ä½œç”¨ä¸æ•ˆæœ
2. Combineræ˜¯å¦èƒ½å¤Ÿæœ‰æ•ˆå‡å°‘Shuffleé˜¶æ®µçš„æ•°æ®é‡ï¼Ÿ
3. åœ¨ä¸åŒçš„keyåˆ†å¸ƒï¼ˆå‡åŒ€åˆ†å¸ƒä¸æ•°æ®å€¾æ–œï¼‰ä¸‹ï¼Œå…¶æ€§èƒ½æå‡æ•ˆæœæœ‰ä½•å·®å¼‚ï¼Ÿ
4. æ˜¯å¦æ‰€æœ‰åœºæ™¯éƒ½é€‚åˆä½¿ç”¨Combinerï¼Ÿ

## è™šæ‹ŸæœºæŸ¥çœ‹ip addr

```
192.168.204.132 master
192.168.204.133 worker01
192.168.204.134 worker02
```

## æ›´æ”¹ä¸»æœºå

```
e.g.

hostnamectl set-hostname master
hostnamectl set-hostname worker01
hostnamectl set-hostname worker02
```

------

## é…ç½®é™æ€ip

```
vi /etc/sysconfig/network-scripts/ifcfg-ens33


//ä¿®æ”¹å†…å®¹
BOOTPROTO="static"

IPADDR=192.168.204.132
NETMASK=255.255.255.0
GATEWAY=192.168.204.2
DNS1=8.8.8.8
```

## ä¿®æ”¹ä¸»æœºæ˜ å°„

```
vi /etc/hosts

å¤åˆ¶ç›¸åº”çš„ip
```

## é‡å¯

```
reboot #åŒæ—¶å»è™šæ‹Ÿæœºé‡å¯å®¢æˆ·ç«¯

ifconfig
ping baidu.com  #æµ‹è¯•ç½‘ç»œæ˜¯å¦è·‘é€š
```

## å®‰è£…sshæœåŠ¡

```
#é…ç½®yumæº
vi /etc/yum.repos.d/CentOS-Base.repo
#å¦‚ä¸‹æ›´æ”¹ï¼š

http://mirrors.aliyun.com/centos/$releasever/os/$basearch/

yum install openssh-server

#ç”Ÿæˆå¯†é’¥
ssh-keygen -t rsa
```

## åˆ›å»ºç›¸å…³ç›®å½•

```
#åˆ›å»ºè½¯ä»¶çš„ç›¸å…³ç›®å½•
#æ”¾ç½®ç›¸å…³æ•°æ®æ–‡ä»¶
mkdir -p /export/data

#è½¯ä»¶çš„å®‰è£…ç›®å½•
mkdir -p /export/servers

#æ”¾ç½®è½¯ä»¶åŒ…
mkdir -p /export/software
```

## æ‹·è´å…¬é’¥åˆ°åŒä¸€å°è™šæ‹Ÿæœºä¸Š

```
#å¤åˆ¶ä¸»èŠ‚ç‚¹å…¬é’¥
ssh-copy-id master 

#åˆ†å‘ç»™åˆ«çš„è™šæ‹Ÿæœº
scp /root/.ssh/authorized_keys worker01:/root/.ssh
scp /root/.ssh/authorized_keys worker02:/root/.ssh
```

## é…ç½®å®‰è£…åŒ…

```bash
yum install lrzszcd -y
```

## JDKå®‰è£…åŠé…ç½®

- å®‰è£…åŒ…ï¼šhttps://www.oracle.com/java/technologies/javase/javase8-archive-downloads.html#license-lightbox jdk-8u181-linux-x64.tar.gz

```
#æŸ¥çœ‹javaç‰ˆæœ¬
java -version

#æŸ¥æ‰¾è™šæ‹Ÿæœºä¸Šçš„æ‰€æœ‰jdk
rpm -qa | grep jdk

#å¸è½½æ‰€æœ‰çš„JDK
rpm -e --nodeps java-1.7.0-openjdk-headless-1.7.0.261-2.6.22.2.el7_8.x86_64
rpm -e --nodeps copy-jdk-configs-3.3-10.el7_5.noarch
rpm -e --nodeps java-1.8.0-openjdk-headless-1.8.0.262.b10-1.el7.x86_64
rpm -e --nodeps java-1.8.0-openjdk-1.8.0.262.b10-1.el7.x86_64
rpm -e --nodeps java-1.7.0-openjdk-1.7.0.261-2.6.22.2.el7_8.x86_64

#å®‰è£…jdk
cd /export/software
#ä¼ è¾“ä¹‹å‰ä¸‹è½½çš„å®‰è£…åŒ…
rz
#è¿›è¡Œè§£å‹ç¼©
tar zxvf jdk-8u181-linux-x64.tar.gz -C /export/servers/
#è¿›è¡Œé‡å‘½å
cd /export/servers
mv jdk1.8.0_181 jdk

#é…ç½®jdkç¯å¢ƒå˜é‡
vi /etc/profile
#æ·»åŠ å¦‚ä¸‹å†…å®¹
export JAVA_HOME=/export/servers/jdk
export PATH=$PATH:$JAVA_HOME/bin
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
#é‡æ–°åŠ è½½ä¸€ä¸‹ç¯å¢ƒå˜é‡
source /etc/profile

#åˆ†å‘jdké…ç½®ç¯å¢ƒç»™å…¶ä»–ä¸¤å°è™šæ‹Ÿæœº
cd jdk
#æ˜¾ç¤ºæ‰€åœ¨è·¯å¾„/export/servers/jdk
pwd 
cd ..
#åˆ†å‘ç›¸å…³æ–‡ä»¶é…ç½®
scp -r /export/servers/jdk worker01:$PWD
scp -r /export/servers/jdk worker02:$PWD
#åˆ†å‘ç¯å¢ƒå˜é‡çš„é…ç½®
scp /etc/profile root@worker01:/etc/profile
scp /etc/profile root@worker02:/etc/profile

#worker01ï¼Œ02é‡æ–°åŠ è½½ä¸€ä¸‹é…ç½®ï¼Œå¯ä»¥çœ‹åˆ°ç›¸å…³çš„javaç‰ˆæœ¬
source /etc/profile
java -version
```

## Hadoopå®‰è£…åŠé…ç½®

https://archive.apache.org/dist/hadoop/core/hadoop-2.7.3/hadoop-2.7.3.tar.gz

```bash 
cd /export/software
#è§£å‹ç¼©åˆ°servers
tar zxvf hadoop-2.7.3.tar.gz -C /export/servers/
#é‡å‘½å
cd ../servers
mv hadoop-2.7.3 hadoop

#é…ç½®ç¯å¢ƒå˜é‡
vi /etc/profile
#æ·»åŠ ä¸€ä¸‹å†…å®¹
export HADOOP_HOME=/export/servers/hadoop
export PATH=:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH
#é‡æ–°åŠ è½½ä¸€ä¸‹ç¯å¢ƒå˜é‡
source /etc/profile
#æŸ¥çœ‹ç‰ˆæœ¬
hadoop version
```

![image-20251124205121153](.\images\image-20251124205121153.png)

## ä¿®æ”¹hadoopä¸‹çš„é…ç½®æ–‡ä»¶

```bash 
cd /export/servers/hadoop/etc/hadoop
#æŸ¥çœ‹ä¸Šè¿°çš„ç›¸å…³æ–‡ä»¶
```

### 1.ä¿®æ”¹hadoop-env.sh

```bash 
vi hadoop-env.sh
#æ·»åŠ å¦‚ä¸‹å†…å®¹ï¼š
export JAVA_HOME=/export/servers/jdk
```

### 2.ä¿®æ”¹core-site.xml

```bash
vi core-site.xml
#æ·»åŠ å¦‚ä¸‹å†…å®¹ï¼›
```

```xm
<property>
	<name>fs.defaultFS</name>
	#å›ºå®šå†™ä¸»æœºå
	<value>hdfs://master:9000</value>
</property>
<property>
	<name>hadoop.tmp.dir</name>
	#è™šæ‹Ÿæœºé‡Œçš„tmpç›®å½•
	<value>/export/servers/hadoop/tmp</value>
</property>
```

### 3.ä¿®æ”¹hdfs-site.xml

```bash
vi hdfs-site.xml
#æ·»åŠ å¦‚ä¸‹å†…å®¹ï¼›
```

```xml
<property>
	<name>dfs.replication</name>
	<value>3</value>
</property>
<property>
	<name>dfs.namenode.secondary.http-address</name>
	#ç¬¬äºŒå°è™šæ‹Ÿæœºçš„åå­—
	<value>worker01:50090</value>
</property>
```

### 4.ä¿®æ”¹mapred-site.xml

```bash
#å…ˆæ‹·è´å¹¶é‡å‘½åä¸€ä¸‹æ–‡ä»¶
cp mapred-site.xml.template mapred-site.xml

vi mapred-site.xml
#æ·»åŠ å¦‚ä¸‹å†…å®¹ï¼›
```

```xml
<property>
	<name>mapreduce.framework.name</name>
	<value>yarn</value>
</property>
```

### 5,ä¿®æ”¹yarn-site.xml

```bash
vi yarn-site.xml
#æ·»åŠ ä»¥ä¸‹å†…å®¹
```

```xml
<property>
	<name>yarn.resourcemanager.hostname</name>
	<value>master</value>
</property>
<property>
	<name>yarn.nodemanager.aux-services</name>
	<value>mapreduce_shuffle</value>
</property>
```

### 6.ä¿®æ”¹slaves

```bash
vi slaves

#å†…å®¹ä¿®æ”¹æˆä¸‰ä¸ªä¸»æœºå
master
worker01
worker02
```

## é›†ç¾¤ä¸»æœºç‚¹é…ç½®åˆ†å‘å­èŠ‚ç‚¹

```bash
scp
scp /etc/profile worker01:/etc/profile
scp /etc/profile worker02:/etc/profile
scp -r /export/ worker01:/
scp -r /export/ worker02:/

#åœ¨å­èŠ‚ç‚¹é‡è½½ç¯å¢ƒå˜é‡é…ç½®
source /etc/profile

#æ ¼å¼åŒ–æ–‡ä»¶ç³»ç»Ÿï¼Œæ³¨ï¼šåªèƒ½åœ¨ç¬¬ä¸€æ¬¡å¯åŠ¨çš„æ—¶å€™è¿›è¡Œhdfsé›†ç¾¤æ ¼å¼åŒ–
hdfs namenode -format
```

## é›†ç¾¤å¯åŠ¨æ“ä½œ

```bash
#å…³é—­é˜²ç«å¢™ï¼Œä¸‰å°éƒ½éœ€è¦å…³é—­
systemctl stop firewalld

#å…³é—­é˜²ç«å¢™å¼€æœºå¯åŠ¨
systemctl disable firewalld

#ä½¿ç”¨å‘½ä»¤ä¸€é”®è„šæœ¬å¯åŠ¨,å…³é—­åˆ™æ”¹ä¸ºstop
start-dfs.sh
start-yarn.sh
start-all.sh

#æŸ¥çœ‹è¿›ç¨‹çš„å¯åŠ¨
start-all.sh
```

### master:50070 æŸ¥çœ‹HDFSé›†ç¾¤çŠ¶æ€

![image-20251125003542119](.\images\image-20251125003542119.png)

### master:8088 æŸ¥çœ‹YARNé›†ç¾¤ç®¡ç†

![image-20251125003455570](.\images\image-20251125003455570.png)
