#!/bin/bash

# åˆ†å¸ƒå¼Hadoopé›†ç¾¤ç®¡ç†è„šæœ¬ï¼ˆä¸»èŠ‚ç‚¹ï¼‰

set -e

CODE_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
cd "$CODE_DIR"

GREEN='\033[0;32m'
RED='\033[0;31m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

print_msg() {
    echo -e "${GREEN}[INFO]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_header() {
    echo -e "${BLUE}========================================${NC}"
    echo -e "${BLUE}$1${NC}"
    echo -e "${BLUE}========================================${NC}"
}

# å¯åŠ¨ä¸»èŠ‚ç‚¹
start_master() {
    print_header "å¯åŠ¨ä¸»èŠ‚ç‚¹æœåŠ¡"
    print_msg "å¯åŠ¨ NameNode, ResourceManager, HistoryServer..."
    docker-compose -f docker-compose-master.yml up -d

    print_msg "ç­‰å¾…æœåŠ¡å¯åŠ¨..."
    sleep 20

    print_msg "ä¸»èŠ‚ç‚¹æœåŠ¡çŠ¶æ€:"
    docker-compose -f docker-compose-master.yml ps

    print_msg "\nä¸»èŠ‚ç‚¹è®¿é—®åœ°å€:"
    echo "  NameNode Web UI:        http://localhost:9870"
    echo "  ResourceManager Web UI: http://localhost:8088"
    echo "  HistoryServer Web UI:   http://localhost:8188"

    print_warning "\nâœ… ä¸»èŠ‚ç‚¹å¯åŠ¨å®Œæˆï¼è¯·é€šçŸ¥ç»„å‘˜å¯åŠ¨å·¥ä½œèŠ‚ç‚¹ã€‚"
}

# åœæ­¢ä¸»èŠ‚ç‚¹
stop_master() {
    print_header "åœæ­¢ä¸»èŠ‚ç‚¹æœåŠ¡"
    docker-compose -f docker-compose-master.yml down
    print_msg "ä¸»èŠ‚ç‚¹å·²åœæ­¢"
}

# æŸ¥çœ‹é›†ç¾¤çŠ¶æ€
status_cluster() {
    print_header "Hadoopåˆ†å¸ƒå¼é›†ç¾¤çŠ¶æ€"

    echo ""
    print_msg "1. ä¸»èŠ‚ç‚¹å®¹å™¨çŠ¶æ€:"
    docker-compose -f docker-compose-master.yml ps

    echo ""
    print_msg "2. HDFS DataNode çŠ¶æ€:"
    docker exec namenode hdfs dfsadmin -report | grep -A 5 "Live datanodes" || echo "æš‚æ— DataNodeè¿žæŽ¥"

    echo ""
    print_msg "3. YARN NodeManager çŠ¶æ€:"
    docker exec resourcemanager yarn node -list || echo "æš‚æ— NodeManagerè¿žæŽ¥"

    echo ""
    print_msg "4. é›†ç¾¤å¥åº·æ£€æŸ¥:"
    docker exec namenode hdfs dfsadmin -report | head -n 20
}

# æŸ¥çœ‹æ‰€æœ‰DataNode
list_datanodes() {
    print_header "DataNode åˆ—è¡¨"
    docker exec namenode hdfs dfsadmin -report | grep "Name:" -A 2
}

# æŸ¥çœ‹æ‰€æœ‰NodeManager
list_nodemanagers() {
    print_header "NodeManager åˆ—è¡¨"
    docker exec resourcemanager yarn node -list -all
}

# åˆå§‹åŒ–HDFS
init_hdfs() {
    print_header "åˆå§‹åŒ–HDFSç›®å½•"

    docker exec namenode hdfs dfs -mkdir -p /user/root
    docker exec namenode hdfs dfs -mkdir -p /input
    docker exec namenode hdfs dfs -mkdir -p /output
    docker exec namenode hdfs dfs -mkdir -p /data
    docker exec namenode hdfs dfs -mkdir -p /tmp

    docker exec namenode hdfs dfs -chmod -R 777 /user
    docker exec namenode hdfs dfs -chmod -R 777 /input
    docker exec namenode hdfs dfs -chmod -R 777 /output
    docker exec namenode hdfs dfs -chmod -R 777 /data
    docker exec namenode hdfs dfs -chmod -R 777 /tmp

    print_msg "HDFSç›®å½•åˆå§‹åŒ–å®Œæˆ"
    docker exec namenode hdfs dfs -ls /
}

# æµ‹è¯•é›†ç¾¤
test_cluster() {
    print_header "é›†ç¾¤åŠŸèƒ½æµ‹è¯•"

    print_msg "1. æµ‹è¯•HDFSå†™å…¥..."
    docker exec namenode bash -c "
        echo 'Hadoop Distributed Cluster Test' > /tmp/test.txt
        hdfs dfs -put -f /tmp/test.txt /test.txt
        hdfs dfs -cat /test.txt
    "

    echo ""
    print_msg "2. è¿è¡ŒMapReduceç¤ºä¾‹ï¼ˆè®¡ç®—PIï¼‰..."
    docker exec namenode hadoop jar \
        /opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar \
        pi 2 100

    echo ""
    print_msg "âœ… æµ‹è¯•å®Œæˆï¼é›†ç¾¤è¿è¡Œæ­£å¸¸ã€‚"
}

# æŸ¥çœ‹æ—¥å¿—
logs_master() {
    local service=$1
    if [ -z "$service" ]; then
        print_msg "æŸ¥çœ‹æ‰€æœ‰ä¸»èŠ‚ç‚¹æœåŠ¡æ—¥å¿—..."
        docker-compose -f docker-compose-master.yml logs --tail=50 -f
    else
        print_msg "æŸ¥çœ‹ $service æ—¥å¿—..."
        docker-compose -f docker-compose-master.yml logs --tail=50 -f "$service"
    fi
}

# è¿›å…¥å®¹å™¨
shell_master() {
    local service=${1:-namenode}
    print_msg "è¿›å…¥ $service å®¹å™¨..."
    print_msg "ä»£ç ç›®å½•: /opt/code"
    docker exec -it "$service" /bin/bash
}

# æ˜¾ç¤ºç»„å‘˜éƒ¨ç½²æŒ‡å—
show_worker_guide() {
    print_header "ðŸ“‹ ç»„å‘˜å·¥ä½œèŠ‚ç‚¹éƒ¨ç½²æŒ‡å—"

    # å°è¯•èŽ·å–æœ¬æœºIP
    LOCAL_IP=$(ipconfig 2>/dev/null | grep "IPv4" | head -1 | awk '{print $NF}' | tr -d '\r')

    cat << EOF

è¯·å°†ä»¥ä¸‹ä¿¡æ¯å‘é€ç»™ç»„å‘˜ï¼š

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ðŸ“ ä¸»èŠ‚ç‚¹ä¿¡æ¯
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ä¸»èŠ‚ç‚¹IP: ${LOCAL_IP:-[è¯·æ‰‹åŠ¨é€šè¿‡ipconfigæŸ¥çœ‹]}

éœ€è¦è®¿é—®çš„åœ°å€ï¼š
- NameNode:        http://${LOCAL_IP:-[ä¸»èŠ‚ç‚¹IP]}:9870
- ResourceManager: http://${LOCAL_IP:-[ä¸»èŠ‚ç‚¹IP]}:8088

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ðŸ“¦ éƒ¨ç½²æ­¥éª¤ï¼ˆç»„å‘˜æ‰§è¡Œï¼‰
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1ï¸âƒ£ å®‰è£…çŽ¯å¢ƒ
   - Docker Desktop
   - WSL2

2ï¸âƒ£ åˆ›å»ºé…ç½®æ–‡ä»¶
   åˆ›å»ºç›®å½•: mkdir hadoop-worker && cd hadoop-worker
   åˆ›å»ºæ–‡ä»¶: docker-compose-worker.yml å’Œ hadoop-worker.env
   (è¯¦ç»†å†…å®¹è§ã€Šå·¥ä½œèŠ‚ç‚¹éƒ¨ç½²ç¬”è®°ã€‹)

3ï¸âƒ£ ä¿®æ”¹IPåœ°å€
   å°†é…ç½®æ–‡ä»¶ä¸­çš„ 192.168.1.100 æ›¿æ¢ä¸º: ${LOCAL_IP:-[ä¸»èŠ‚ç‚¹IP]}

4ï¸âƒ£ å¼€æ”¾é˜²ç«å¢™ç«¯å£
   ç«¯å£: 9864, 9866, 9867, 8042

5ï¸âƒ£ å¯åŠ¨å·¥ä½œèŠ‚ç‚¹
   docker-compose -f docker-compose-worker.yml up -d

6ï¸âƒ£ éªŒè¯è¿žæŽ¥
   è®¿é—®ä¸»èŠ‚ç‚¹Webç•Œé¢æŸ¥çœ‹DataNodeå’ŒNodeManageræ˜¯å¦å‡ºçŽ°

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

EOF
}

# å¸®åŠ©ä¿¡æ¯
show_help() {
    cat << EOF
åˆ†å¸ƒå¼Hadoopé›†ç¾¤ç®¡ç†è„šæœ¬ï¼ˆä¸»èŠ‚ç‚¹ï¼‰

ç”¨æ³•: ./scripts/cluster-manager.sh [å‘½ä»¤]

å‘½ä»¤:
  start           å¯åŠ¨ä¸»èŠ‚ç‚¹æœåŠ¡
  stop            åœæ­¢ä¸»èŠ‚ç‚¹æœåŠ¡
  status          æŸ¥çœ‹é›†ç¾¤çŠ¶æ€
  datanodes       æŸ¥çœ‹æ‰€æœ‰DataNode
  nodemanagers    æŸ¥çœ‹æ‰€æœ‰NodeManager
  init            åˆå§‹åŒ–HDFSç›®å½•
  test            æµ‹è¯•é›†ç¾¤åŠŸèƒ½
  logs [service]  æŸ¥çœ‹æ—¥å¿—
  shell [service] è¿›å…¥å®¹å™¨
  worker-guide    æ˜¾ç¤ºç»„å‘˜éƒ¨ç½²æŒ‡å—
  help            æ˜¾ç¤ºæ­¤å¸®åŠ©

ç¤ºä¾‹:
  ./scripts/cluster-manager.sh start         # å¯åŠ¨ä¸»èŠ‚ç‚¹
  ./scripts/cluster-manager.sh status        # æŸ¥çœ‹é›†ç¾¤çŠ¶æ€
  ./scripts/cluster-manager.sh datanodes     # æŸ¥çœ‹æ‰€æœ‰æ•°æ®èŠ‚ç‚¹
  ./scripts/cluster-manager.sh worker-guide  # èŽ·å–ç»„å‘˜éƒ¨ç½²æŒ‡å—

EOF
}

# ä¸»å‡½æ•°
main() {
    case "${1:-help}" in
        start)
            start_master
            ;;
        stop)
            stop_master
            ;;
        status)
            status_cluster
            ;;
        datanodes)
            list_datanodes
            ;;
        nodemanagers)
            list_nodemanagers
            ;;
        init)
            init_hdfs
            ;;
        test)
            test_cluster
            ;;
        logs)
            logs_master "$2"
            ;;
        shell)
            shell_master "$2"
            ;;
        worker-guide)
            show_worker_guide
            ;;
        help|--help|-h)
            show_help
            ;;
        *)
            print_error "æœªçŸ¥å‘½ä»¤: $1"
            show_help
            exit 1
            ;;
    esac
}

main "$@"