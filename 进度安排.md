### **第一周（Day 1-7）：环境搭建 + 文献调研**

**任务清单：**

1. 环境搭建

   （2人，3-4天）

   - 搭建Hadoop集群（≥3节点）
   - 配置YARN、HDFS
   - 验证MapReduce作业能正常运行
   - 文档记录集群配置信息

2. 文献调研 + 实验设计

   （2人，3-4天）

   - 研究Combiner机制原理
   - 调研类似研究的实验方法
   - 确定测试场景（WordCount、数据倾斜场景等）
   - 设计数据生成策略（均匀分布、不同倾斜度）

### **第二周（Day 8-14）：代码开发 + 数据准备**

**任务清单：**

1. 编写MapReduce作业

   （2人，4-5天）

   - 实现带Combiner和不带Combiner的版本
   - 添加性能监控代码（记录Shuffle数据量、时间等）
   - 编写数据生成程序（生成不同倾斜度的数据集）

2. 数据集准备

   （1人，2-3天）

   - 生成均匀分布数据集
   - 生成不同倾斜度数据集（轻度、中度、重度倾斜）
   - 验证数据集特征

3. 测试框架搭建

   （1人，2-3天）

   - 编写自动化测试脚本
   - 实现指标收集工具

### **第三周（Day 15-21）：实验执行**

**任务清单：**

1. 运行实验

   （全员，5-6天）

   - 在各数据集上运行实验
   - 记录所有指标数据
   - 截图保存关键信息
   - 处理异常情况，必要时重跑

2. 数据整理

   （1人，持续进行）

   - 整理实验原始数据
   - 初步数据分析

### **第四周（Day 22-28）：分析报告 + 收尾**

**任务清单：**

1. 数据分析

   （2人，3-4天）

   - 绘制对比图表
   - 分析性能差异原因
   - 总结适用场景

2. 撰写报告

   （2人，3-4天）

   - 完善README.md
   - 整理代码注释
   - 准备答辩材料

3. 代码整理

   （全员，2天）

   - 代码审查
   - 补充文档
   - 最终测试